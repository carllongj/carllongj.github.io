## kafka
### 安装和配置
* `下载kafka,解压和进入到目录`
    * `wget https://www.apache.org/dyn/closer.cgi?path=/kafka/2.4.1/kafka_2.12-2.4.1.tgz`
    * `tar kafka_2.12-2.4.1.tgz && cd kafka_2.12-2.4.1`
* 单机版启动`kafka服务`
    * 首先启动`zookeeper`.
        * 修改 `config/zookeeper.properties` 配置文件
            * 配置 `zookeeper` 的 `dataDir` 属性的路径地址.
            * 配置 `zookeeper` 的 `dataLogDir` 属性的路径地址.
        * 启动`zookeeper`.
            * `bin/zookeeper-server-start.sh -daemon config/zookeeper.properties`
    * 启动kafka服务
        * 修改 `config/server.properties` 配置文件
            * 配置 `broker.id`,每一个 `broker.id` 必须是不重复的整数,用以标识一个`broker`.
            * 配置 `listeners` 配置项, 该项用以配置当前 `broker` 的监听地址.
        * 启动 `kafka`
            * `bin/kafka-server-start.sh -daemon config/server.properties`  
* 集群版配置,通过`多个配置文件`来启动不同的kafka实例.
    * 可以在`一台机器`启动`多个kafka实例`,也可以在`多台机器`上启动`kafka实例`
    * 配置文件
        * 修改 `broker.id` ,集群中的每一个 `broker` 实例的`id不能重复`.
        * 修改 `listeners` 配置项,指定不同的`主机名称`或者`端口`.
        * 修改 `log.dirs` 配置项,单机多实例保证不同的`broker`存储路径在不同的目录.
    * 通过 `kafka-server-start.sh` 依次启动`不同的配置文件`的不同实例.
* `kafka脚本` 使用
    * `bin/kafka-topics.sh`
        * 创建新的 `topic`
            * `bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic topic`
                * `--bootstrap-server` 用于指定连接的 `kafka` 集群配置,包含一个或者多个的 `kafka` 连接地址.`该选项必须要指定`.
                * `--replication-factor` 用于指定 `partition` 的副本个数.
                * `--partitions` 用于指定 `partition` 的个数.
                * `--topic` 用于指定 `topic` .
        * 删除 `topic`
            * `bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic topic`
        * 列出所有的 `topic`
            * `bin/kafka-topics.sh --bootstrap-server localhost:9092 --list`
        * 查看指定 `topic` 的信息
            * `bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic topic`
                * `--topic` 若未指定对应的`topic`,则将展示所有的topic信息.
                * `Isr`(`in-sync-replicas`) 表示当前 `partition` 的可用副本.
    * `bin/kafka-console-producer.sh`
        * 通过控制台来产生消息,执行命令后进入 `输入消息`的 `repl`
            * `bin/kafka-console-producer.sh --broker-list localhost:9092 --topic topic`
                * `--broker-list` 用于指定`broker`连接地址,包含一个或者多个 `broker` 地址,多个使用逗号分隔.
                * `--topic` 用于指定 `topic`.
    * `bin/kafka-console-consumer.sh`
        * 通过控制台来消费消息,执行命令后进入 `消息打印` 
            * `bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic --from-beginning`
                * `--bootstrap-server` 用于指定 `kafka` 的连接地址.
                * `--topic` 用于指定 `topic`.
                * `--from-beginning` 用于标识当前消费者从`第一条消息`开始消费.
                * `--offset` 用于指定从起始位置开始消费(`不是单独一条消息`)
                * `--partition` 用于指定消费的分区,当指定`--offset`时,`partition` 必须要指定,第一个分区从`0`开始.
* `kafka` 中的概念定义
    * `Producer`,消息的生产者,是产生消息的来源.
    * `broker`,`Broker` 是`kafka` 实例,每个服务器上可以有一个或者多个`kafka实例`.`kafka集群`的`每一个broker`都有一个不重复的编号.
    * `topic`,消息的主题,就是一类数据的集合,`kafka`的数据就`topic`进行分类存储.
    * `partition`,`topic`的分区,每一个`topic`都可以有多个分区,分区的作用是做负载.同一个topic在不同的分区数据是不重复的.
    * `replication`,副本,每一个分区都可以有多个副本.`partition`若存在多个副本,则一个partition将存在主从模式.
        * 一个`partition`将成为`Leader`,其它的 `replication` 将成为 `Follower`.
        * 消费者和生产者都是从`Leader`进行读写数据,不与`Follower`交互.
        * 如果一个分区的`Leader`挂掉,那么就只会从剩下的`Folloers`中选择一个`Leader`,并且不会在其它`broker`中重启副本(`数据迁移,网络IO开销大`).
    * `consumer`,消费者,即`消息的消费方`,是消息的出口.
    * `consumer group`,`多个消费者`组成一个消费者组.
        * 同一个消费者组对同一条消息`只消费一次`.
        * 每一个分区只能由消费组内的一个消费者(`consumer`)来消费,可以由不同的消费组来消费.
        * `partition` 数量决定了每一个 `consumer group`中的并发消费者的最大数量.
            * 如果一个`topic只有两个分区`,而`消费者组`有`四个消费者`,也会有两个空闲的消费者.
            * 如果一个`topic有四个分区`,而`消费者组`有`四个消费者`,那么将会到达`最大并发量4`.
            * 如果一个`topic有四个分区`,而`消费者组`有`两个消费者`,那么`每一个消费者`将会消费`两个分区`的数据.
        * 某一个主题下的分区数,对于消费该主题的同一个消费者组下的消费数量,应该`小于等于该主题下的分区数`.
        * 同一个分区下的数据,在同一时刻,不能`由同一个消费者组下的不同消费者`消费.
        * 实际的应用中,应该保证`消费者组的消费者个数`与`topic的分区个数`保持一致.
* Kafka机制
    * 数据发布工作流.
        1. 首先从集群中获取对应的分区`Leader`信息.
        2. `Producer` 将消息发送给 `Leader`.
        3. `Leader` 将消息写入到本地文件.
        4. `Followers` 从 `Leader` 进行 `pull消息`.
        5. `Followers` 将消息写入本地后,向`Leader`发送`ACK`.
        6. `Leader` 收到所有副本的`ACK`后向 `Producer` 发送 `ACK`.
    * ACK应答机制
        * 生产者在向队列中写入数据时可以设置参数来确定是否确认 `kafka` 是否接收到数据.这个参数可以设置为.
            * `0`,表示`producer`往集群中发送数据时不需要等到集群的返回,不确定消息是否发送成功.
            * `1`,表示 `Producer`往集群中发送数据只要 `Leader`应答一条就可以发送下一条,只确保`Leader`发送成功.
            * `all`,表示`Producer`往集群发送数据需要所有的 `Follower`都完成从`Leader`的同步才会发送下一条,确保完全备份.
    * 数据存储.
        * 数据的存储路径是由 `kafka` 实例的配置文件 `server.properties` 中的 `log.dirs` 配置指定的.
            * 该目录下会由kafka来进行创建一些文件夹.名称为 `topic-partition`(`主题名称-分区编号`)
        * `Partition` 中划分为多个 `Segment`,每一个`Segment`包含了 `.log`,`.index`, `.timeindex`文件.
        * `Segment` 结构.
            * `Segment` 会根据log日志的大小进行扩展,默认为`1G`(由配置项 `log.segment.bytes`)
                * 当`.log`文件已经到达指定大小,则后续的数据将写入到另一个 `Segment` 文件.
            * `文件结构`
                * `.log` 文件主要用于存储消息内容.
                    * 存储的内容为消息,是由 `kafka` 包装的一个数据结构(`Message`).
                        
                        |  Message 物理结构     |   字段说明                             |
                        |:---------------------:|:-------------------------------------:|
                        |  8 byte offset        | message 在 partition 中的索引位置      |
                        |  4 byte message size  | 消息的大小                             |
                        |  4 byte CRC32         | 循环冗余校验                           |
                        |  1 byte magic         | kafka服务程序协议版本号                 |
                        |  1 byte attribute     | 表示独立版本或者标识压缩类型或者编码类型  |
                        |  4 byte key length    | 表示key的长度,当 `为-1时`, key 表示无值 |
                        |  key                  | k的值,可选,长度由前一个字段指定          |
                        |  4 byte payload length| 消息的长度                             |
                        |  value                | 消息数据                               |
                    * `.log` 文件中存储的都是这种格式的内容. 
                * `.index` 文件用于存储消息的索引,加速消息的检索.
                    * 索引文件中是消息(`Message`)相对 `offset` 与 `消息实际物理偏移地址`.
                    * 索引文件全部是存储的这种`条目`,加快索引.
                * `.timeindex` 用于存储消息的时间索引.
            * `命名规则`
                * `offset` 值作为了文件名的一部分,数值最大为`64位大小`,20位数字字符长度,没有数字`使用0填充`.
                * `partition` 全局的第一个 `Segment` 从 `0` 开始,后续每一个 `Segment` 为上一个全局 `partition` 的最大`offset`(偏移`message`)数.
                * 一个`Segment`下所有文件(`.log`,`.index`,`.timeindex`)文件名称是相同的.
    * `Message` 检索过程(指定一个`offset`)
        1. 根据 `offset` 找到对应的 `Segment`,(由于文件名记录的是上一个 `Segment` 的`offset`),可以通过二分查找找到对应的`Segment`.
        2. 打开找到的`Segment`,并且使用其 `.index` 文件,来检索对应的 `offset`的 `Message`.
            * 由于`.index` 文件使用稀疏索引,存储的是相对`offset` 和 `Message` 物理偏移量的关系.
            * 并且有可能不能直接找到对应的偏移索引,故同样使用二分查找,找到最合适的一个`索引条目`.
        3. 通过索引条目,找到物理偏移量,开始顺序扫描到对应的 `Message`,检索完成.
    * `消费者记录自己`的位置.
        * 消费者消费到的 `offset` 已经直接维护到了 kakfa 集群的 `__consumer_offsets` 这个 `topic` 中了.